

---

# ðŸŽ¨ **BM25 Visual Diagram Set**

---

## 1ï¸âƒ£ **BM25 Score Spectrum**

A simple visual to show that BM25 scores live on a continuum â€” and negative values are normal.

```
          BM25 SCORE RANGE
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Negative               Zero             Positive
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      -8   -5   -3   -1    0    +1   +3   +6   +10
                  â†‘
          Higher is better
```

Key teaching moment:  
Even in the negative zone, **-1 beats -5**.

---

## 2ï¸âƒ£ **IDF Intuition: Rarity vs Commonness**

A diagram showing how IDF flips sign depending on how common a term is.

```
          TERM RARITY â†’ IDF VALUE
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | Rare Terms     | Medium Terms | Common Terms  |
 | (n small)      | (n â‰ˆ N/2)    | (n large)     |
 |                |              |               |
 |   + Positive   |     Zero     |   - Negative  |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Examples:
Rare â†’ "neutrino"  
Medium â†’ "database"  
Common â†’ "the"
```

---

## 3ï¸âƒ£ **Why Negative Scores Happen (Visual Math)**

A visual breakdown of the IDF fraction.

```
IDF = ln( (N - n + 0.5) / (n + 0.5) )

When n is small:
   (N - n + 0.5)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  > 1   â†’ ln > 0
    (n + 0.5)

When n â‰ˆ N/2:
   (N - n + 0.5)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  = 1   â†’ ln = 0
    (n + 0.5)

When n is large:
   (N - n + 0.5)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  < 1   â†’ ln < 0
    (n + 0.5)
```

This is the exact moment students go â€œahhh, okay.â€

---

## 4ï¸âƒ£ **Document Ranking With Negative Scores**

A visual showing how ranking still works even when all scores are negative.

```
Query: "the programming language"

Document Scores:
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | Document       | BM25 Score   |
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 | Doc 2          |   -4.8       |  â† Best match
 | Doc 1          |   -5.2       |
 | Doc 3          |    0.0       |  â† No match
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ranking is based on:
   -4.8  >  -5.2  >  0.0
```

This diagram helps students detach from the idea that â€œnegative = badâ€.

---

## 5ï¸âƒ£ **BM25 as â€œBonus Points + Penalty Pointsâ€**

A conceptual diagram showing how BM25 adds up contributions.

```
BM25 Score = Î£ (IDF Ã— Term Frequency Weight)

For each term:
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | Rare Term     | + Bonus (positive IDF)       |
 | Common Term   | - Penalty (negative IDF)     |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Final Score = Bonuses + Penalties
```

This is a great mental model for beginners.

---

## 6ï¸âƒ£ **BM25 vs TFâ€‘IDF (Visual Comparison)**

```
              TFâ€‘IDF vs BM25
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | TFâ€‘IDF:                                       |
 |   - Linear term frequency                     |
 |   - No length normalization                   |
 |   - Simpler but less realistic                |
 |                                               |
 | BM25:                                         |
 |   - Saturating term frequency (diminishing)   |
 |   - Length normalization                      |
 |   - Better ranking quality                    |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7ï¸âƒ£ **When Scores Become Positive, Zero, or Negative**

```
              WHEN DO SCORES TAKE EACH SIGN?
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | Positive â†’ Rare terms                         |
 | Zero     â†’ No matching terms OR balanced IDF  |
 | Negative â†’ Very common terms                  |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8ï¸âƒ£ **BM25 Pipeline Overview**

A highâ€‘level diagram showing how BM25 processes a query.

```
          BM25 RANKING PIPELINE
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 | 1. Query Terms                                |
 | 2. For each document:                         |
 |      - Count term frequency                   |
 |      - Compute IDF                            |
 |      - Apply length normalization             |
 |      - Combine contributions                  |
 | 3. Produce BM25 score                         |
 | 4. Sort documents by score                    |
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This helps students see BM25 as a sequence, not a black box.

---
```markdown
# ðŸ” From TF & IDF to BM25  
*A practical explainer for developers learning Full Text Search*

---

## 1. Big picture: what are we trying to do?

When you type a query like:

> `python programming`

into a search box, the search engine needs to answer:

> **â€œWhich documents are most relevant to this query?â€**

To do that, it uses **scoring functions**.  
Three core ideas youâ€™ll see again and again are:

- **TF** â€“ Term Frequency  
- **IDF** â€“ Inverse Document Frequency  
- **BM25** â€“ A modern ranking function that builds on TF & IDF

Weâ€™ll build up from TF â†’ IDF â†’ TFâ€‘IDF â†’ BM25 with concrete numbers.

---

## 2. Term Frequency (TF)

### 2.1 Intuition

**TF** measures *how often* a term appears in a document.

- If a term appears more times in a document, that document is *probably* more about that term.
- But TF alone doesnâ€™t know whether the term is common or rare in the whole collection.

### 2.2 Simple definition

For a term \( t \) in a document \( d \):

\[
TF(t, d) = \text{number of times } t \text{ appears in } d
\]

Sometimes we normalize it (e.g., divide by document length), but letâ€™s start simple.

### 2.3 Example: TF in three documents

Suppose we have three documents:

- **Doc 1:** `"Python is a great programming language. Python is popular."`  
- **Doc 2:** `"Java is a programming language."`  
- **Doc 3:** `"Cooking recipes and kitchen tips."`

Letâ€™s compute TF for the term **"python"**:

- Doc 1: `"Python"` appears **2** times â†’ \( TF(\text{python}, \text{Doc 1}) = 2 \)  
- Doc 2: `"Python"` appears **0** times â†’ \( TF = 0 \)  
- Doc 3: `"Python"` appears **0** times â†’ \( TF = 0 \)

So TF tells us: **Doc 1 talks about Python, the others donâ€™t.**

---

## 3. Inverse Document Frequency (IDF)

### 3.1 Intuition

**IDF** measures *how rare or common* a term is across the **whole collection**.

- If a term appears in **many** documents, itâ€™s less useful for distinguishing them (e.g., â€œtheâ€, â€œisâ€).
- If a term appears in **few** documents, itâ€™s more informative (e.g., â€œneuralâ€, â€œdockerâ€, â€œWordPressâ€).

IDF gives **more weight to rare terms** and **less weight to common terms**.

### 3.2 Classic IDF formula

Let:

- \( N \) = total number of documents  
- \( n \) = number of documents that contain the term \( t \)

A common IDF formula is:

\[
IDF(t) = \log \left( \frac{N}{n} \right)
\]

BM25 uses a slightly smoothed version:

\[
IDF(t) = \ln \left( \frac{N - n + 0.5}{n + 0.5} \right)
\]

Weâ€™ll use the BM25-style IDF in our examples.

### 3.3 Example: IDF for â€œpythonâ€ and â€œprogrammingâ€

Using our 3 documents:

- **Doc 1:** `"Python is a great programming language. Python is popular."`  
- **Doc 2:** `"Java is a programming language."`  
- **Doc 3:** `"Cooking recipes and kitchen tips."`

Total documents:  
\[
N = 3
\]

#### Term: `"python"`

- Appears in Doc 1 only â†’ \( n_{\text{python}} = 1 \)

\[
IDF(\text{python}) = \ln \left( \frac{3 - 1 + 0.5}{1 + 0.5} \right)
= \ln \left( \frac{2.5}{1.5} \right)
\approx \ln(1.6667)
\approx 0.51
\]

So `"python"` has a **positive IDF** â†’ itâ€™s relatively rare and informative.

#### Term: `"programming"`

- Appears in Doc 1 and Doc 2 â†’ \( n_{\text{programming}} = 2 \)

\[
IDF(\text{programming}) = \ln \left( \frac{3 - 2 + 0.5}{2 + 0.5} \right)
= \ln \left( \frac{1.5}{2.5} \right)
= \ln(0.6)
\approx -0.51
\]

So `"programming"` has a **negative IDF** â†’ itâ€™s common in this tiny collection.

> ðŸ”‘ Key idea:  
> - Rare term â†’ IDF positive  
> - Very common term â†’ IDF can be zero or negative  
> - Thatâ€™s normal and expected

---

## 4. TFâ€‘IDF: combining TF and IDF

### 4.1 Intuition

TF tells us:  
> â€œHow much does this document talk about this term?â€

IDF tells us:  
> â€œHow special is this term across all documents?â€

**TFâ€‘IDF** combines them:

\[
TF\text{-}IDF(t, d) = TF(t, d) \times IDF(t)
\]

So a term gets a **high score** if:

- It appears **often** in the document (high TF), and  
- It appears in **few** documents overall (high IDF)

### 4.2 Example: TFâ€‘IDF for â€œpythonâ€

From before:

- \( TF(\text{python}, \text{Doc 1}) = 2 \)  
- \( IDF(\text{python}) \approx 0.51 \)

\[
TF\text{-}IDF(\text{python}, \text{Doc 1}) = 2 \times 0.51 \approx 1.02
\]

For Doc 2 and Doc 3:

- \( TF = 0 \) â†’ TFâ€‘IDF = 0

So `"python"` strongly boosts Doc 1 and does nothing for the others.

---

## 5. BM25: a smarter TFâ€‘IDF

### 5.1 Why BM25?

TFâ€‘IDF is good, but it has some limitations:

- TF grows linearly: the 10th occurrence of a term is treated as important as the 1st.
- It doesnâ€™t handle document length very well (long documents naturally have more terms).

**BM25** improves on this by:

1. Making TF **saturate** (diminishing returns for repeated terms)  
2. Normalizing for **document length**  
3. Using a smoothed IDF (which can be negative for very common terms)

### 5.2 BM25 formula (simplified)

For a single term \( t \) in document \( d \):

\[
BM25(t, d) = IDF(t) \cdot \frac{TF(t, d) \cdot (k_1 + 1)}{TF(t, d) + k_1 \cdot \left(1 - b + b \cdot \frac{|d|}{avgdl}\right)}
\]

Where:

- \( TF(t, d) \) = term frequency in document  
- \( |d| \) = document length (number of terms)  
- \( avgdl \) = average document length in the collection  
- \( k_1 \) = controls TF saturation (commonly around 1.2â€“2.0)  
- \( b \) = controls length normalization (commonly around 0.75)  
- \( IDF(t) \) = the BM25-style IDF we used earlier

For a multi-term query, BM25 just **sums** over all query terms:

\[
BM25(q, d) = \sum_{t \in q} BM25(t, d)
\]

---

## 6. Worked BM25 example (step by step)

Letâ€™s use a small, concrete example.

### 6.1 Our documents

- **Doc 1:** `"Python is a great programming language. Python is popular."`  
- **Doc 2:** `"Java is a programming language."`  
- **Doc 3:** `"Cooking recipes and kitchen tips."`

Letâ€™s approximate token counts:

- Doc 1: `"Python(1) is(2) a(3) great(4) programming(5) language.(6) Python(7) is(8) popular.(9)"`  
  â†’ \( |d_1| = 9 \)  
- Doc 2: `"Java(1) is(2) a(3) programming(4) language.(5)"`  
  â†’ \( |d_2| = 5 \)  
- Doc 3: `"Cooking(1) recipes(2) and(3) kitchen(4) tips.(5)"`  
  â†’ \( |d_3| = 5 \)

Average document length:

\[
avgdl = \frac{9 + 5 + 5}{3} = \frac{19}{3} \approx 6.33
\]

Weâ€™ll use:

- \( k_1 = 1.5 \)  
- \( b = 0.75 \)

### 6.2 Query: `"python programming"`

Weâ€™ll compute BM25 for **Doc 1** only (you can extend this to others).

#### Step 1: IDF values

We already computed:

- `"python"` appears in 1 document â†’ \( n_{\text{python}} = 1 \)

\[
IDF(\text{python}) = \ln \left( \frac{3 - 1 + 0.5}{1 + 0.5} \right)
= \ln \left( \frac{2.5}{1.5} \right)
\approx 0.51
\]

- `"programming"` appears in 2 documents â†’ \( n_{\text{programming}} = 2 \)

\[
IDF(\text{programming}) = \ln \left( \frac{3 - 2 + 0.5}{2 + 0.5} \right)
= \ln \left( \frac{1.5}{2.5} \right)
\approx -0.51
\]

So:

- `"python"` â†’ **positive** IDF  
- `"programming"` â†’ **negative** IDF

#### Step 2: TF values in Doc 1

- `"python"` appears **2** times â†’ \( TF(\text{python}, d_1) = 2 \)  
- `"programming"` appears **1** time â†’ \( TF(\text{programming}, d_1) = 1 \)

#### Step 3: Length normalization factor

For Doc 1:

\[
|d_1| = 9, \quad avgdl \approx 6.33
\]

Compute the length factor:

\[
L = 1 - b + b \cdot \frac{|d_1|}{avgdl}
= 1 - 0.75 + 0.75 \cdot \frac{9}{6.33}
\]

First:

\[
\frac{9}{6.33} \approx 1.42
\]

Then:

\[
L = 0.25 + 0.75 \cdot 1.42
= 0.25 + 1.065
= 1.315
\]

Weâ€™ll use \( L \approx 1.315 \).

#### Step 4: BM25 contribution for `"python"` in Doc 1

\[
BM25(\text{python}, d_1) = IDF(\text{python}) \cdot \frac{TF \cdot (k_1 + 1)}{TF + k_1 \cdot L}
\]

Plug in:

- \( IDF(\text{python}) \approx 0.51 \)  
- \( TF = 2 \)  
- \( k_1 = 1.5 \)  
- \( L \approx 1.315 \)

Compute numerator:

\[
TF \cdot (k_1 + 1) = 2 \cdot (1.5 + 1) = 2 \cdot 2.5 = 5
\]

Compute denominator:

\[
TF + k_1 \cdot L = 2 + 1.5 \cdot 1.315
\]

First:

\[
1.5 \cdot 1.315 \approx 1.9725
\]

Then:

\[
2 + 1.9725 = 3.9725
\]

So the fraction:

\[
\frac{5}{3.9725} \approx 1.259
\]

Now multiply by IDF:

\[
BM25(\text{python}, d_1) \approx 0.51 \times 1.259 \approx 0.64
\]

#### Step 5: BM25 contribution for `"programming"` in Doc 1

\[
BM25(\text{programming}, d_1) = IDF(\text{programming}) \cdot \frac{TF \cdot (k_1 + 1)}{TF + k_1 \cdot L}
\]

Plug in:

- \( IDF(\text{programming}) \approx -0.51 \)  
- \( TF = 1 \)  
- \( k_1 = 1.5 \)  
- \( L \approx 1.315 \)

Numerator:

\[
TF \cdot (k_1 + 1) = 1 \cdot 2.5 = 2.5
\]

Denominator:

\[
TF + k_1 \cdot L = 1 + 1.5 \cdot 1.315
\]

We already computed \( 1.5 \cdot 1.315 \approx 1.9725 \), so:

\[
1 + 1.9725 = 2.9725
\]

Fraction:

\[
\frac{2.5}{2.9725} \approx 0.841
\]

Now multiply by IDF:

\[
BM25(\text{programming}, d_1) \approx -0.51 \times 0.841 \approx -0.43
\]

#### Step 6: Total BM25 score for the query

For query `"python programming"`:

\[
BM25(q, d_1) = BM25(\text{python}, d_1) + BM25(\text{programming}, d_1)
\]

\[
\approx 0.64 + (-0.43) = 0.21
\]

So Doc 1 gets a **positive** overall BM25 score for this query, even though one term had a **negative** IDF.

If you compute the same for Doc 2 and Doc 3, youâ€™ll see:

- Doc 1 will still rank highest for `"python programming"`  
- Doc 2 may get some score from `"programming"` only  
- Doc 3 will likely get **0** (no matching terms)

> ðŸ”‘ Key lesson:  
> BM25 is about **relative ranking**, not about scores being positive or negative.

---

## 7. Connecting this to Full Text Search (FTS)

In systems like **MySQL FULLTEXT**, **Elasticsearch**, **OpenSearch**, and search plugins for **WordPress**, the engine:

1. Breaks documents into terms (tokenization)  
2. Builds an index mapping terms â†’ documents  
3. For a query, finds candidate documents containing the terms  
4. Computes a score (often BM25) for each document  
5. Sorts documents by score and returns the top results

You donâ€™t usually see TF, IDF, and BM25 directlyâ€”but theyâ€™re working behind the scenes to:

- Reward documents that use the query terms more often (TF)  
- Reward rare, informative terms (IDF)  
- Balance term frequency and document length (BM25)

---

## 8. Summary for your mental model

- **TF**:  
  > â€œHow much does this document talk about this term?â€

- **IDF**:  
  > â€œHow special is this term across all documents?â€

- **TFâ€‘IDF**:  
  > â€œHigh if the term is frequent in this document and rare overall.â€

- **BM25**:  
  > â€œA smarter TFâ€‘IDF that saturates TF and normalizes for document length.â€

- **Negative IDF / BM25 scores**:  
  > Normal, expected, and not a problem.  
  > Only **relative order** matters: higher score = more relevant.

If you remember just one sentence:

> **BM25 is a ranking function built on TF and IDF that tells us which documents are most relevant to a queryâ€”regardless of whether the scores are positive or negative.**
```

