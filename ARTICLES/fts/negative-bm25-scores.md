# ğŸ” **Understanding BM25 Scores: Why Negative Numbers Are Totally Normal**  
*A lecture for developers learning modern search ranking*

## ğŸ¬ **Opening Intuition: What Is BM25 Trying to Do?**

BM25 is a **relevance scoring function**. Its job is simple:

> **Given a query, how relevant is each document?**

But BM25 doesnâ€™t care about absolute numbers.  
It only cares about **relative ranking**.

Think of BM25 like a judge in a talent show:

- It doesnâ€™t matter whether the judge scores contestants 1â€“10 or -10â€“0  
- What matters is **who ranks higher**

This is why **negative scores are not a problem** â€” theyâ€™re just part of the math.

---

# ğŸ”¢ **Understanding BM25 Scores**

## â­ Negative Scores Are Normal

BM25 scores can be **positive, negative, or zero**.  
The only rule that matters:

> **Higher scores = better matches (even if theyâ€™re negative)**

This is the part that confuses beginners, so emphasize it early and often.

---

# ğŸ“Š **Interpreting BM25 Scores**

### **Positive Scores**  
These happen when the query terms are **rare** across your collection.

- Rare terms â†’ high IDF â†’ positive BM25  
- Example: Searching for â€œquantumâ€ in a blog collection

### **Negative Scores**  
These happen when the query terms are **very common**.

- Common terms â†’ negative IDF â†’ negative BM25  
- Example: Searching for â€œtheâ€ or â€œprogrammingâ€

### **Zero Scores**  
These happen when:

- The document contains **none** of the query terms  
- Or the terms are so common that the math cancels out

---

# ğŸ§® **Why Negative Scores Happen (The Math Intuition)**

BM25 uses the IDF formula:

```
IDF = ln((N - n + 0.5) / (n + 0.5))
```

Where:

- **N** = total number of documents  
- **n** = number of documents containing the term  

If a term appears in **more than half** of your documents, the fraction becomes < 1, and:

- ln(<1) = negative number  
- â†’ negative IDF  
- â†’ negative BM25  

This is expected and correct.

---

# ğŸ§  **Mental Model: Think of IDF Like â€œUniqueness Pointsâ€**

- Rare terms earn **bonus points**  
- Common terms earn **penalty points**  
- BM25 adds up all the bonuses and penalties  

If all your query terms are common, you get a **negative total**, but the ranking still works.

---

# ğŸ“ˆ **Example Breakdown**

| Document | "the" | "programming" | "language" | BM25 |
|---------|-------|----------------|------------|------|
| Doc 1   | Yes   | Yes            | Yes        | -5.2 |
| Doc 2   | Yes   | Yes            | No         | -4.8 |
| Doc 3   | No    | No             | No         | 0.0  |

Ranking:

1. Doc 2 (best)  
2. Doc 1  
3. Doc 3 (worst)

Even though Doc 2 has a negative score, itâ€™s still the **best match**.

---

# ğŸ§­ **When Youâ€™ll See Each Score Type**

### **Positive Scores**
- Rare terms  
- Technical vocabulary  
- Small document sets  

### **Negative Scores**
- Common words  
- Terms appearing in most documents  
- Broad/general vocabulary  

### **Zero Scores**
- No matching terms  
- Completely unrelated content  

---

# ğŸ› ï¸ **Practical Experiments (Perfect for WordPress Developers)**

### **1. Positive Score Experiment**
Documents:  
- â€œPython is greatâ€  
- â€œJava is fastâ€  
- â€œC++ is powerfulâ€  

Query: **python** â†’ positive score

### **2. Negative Score Experiment**
Documents:  
- â€œProgramming in Pythonâ€  
- â€œProgramming in Javaâ€  
- â€œProgramming in C++â€  

Query: **programming** â†’ negative scores

### **3. Zero Score Experiment**
Documents:  
- â€œPython programmingâ€  
- â€œJava codingâ€  
- â€œC++ developmentâ€  

Query: **cooking recipes** â†’ zero

---

# ğŸ§¬ **BM25 vs TFâ€‘IDF (A Quick Comparison)**

Students often ask this, so itâ€™s worth adding:

| Feature | TFâ€‘IDF | BM25 |
|--------|--------|------|
| Term frequency | Linear | Saturates (diminishing returns) |
| Document length | Not handled well | Normalized |
| Ranking quality | Good | Better |
| Negative scores | Yes | Yes |
| Used in modern search engines | Rarely | Very common |

BM25 is essentially a **smarter, more realistic TFâ€‘IDF**.

---

# ğŸ§ª **Mini Exercise for Students**

Ask them to compute IDF for a term appearing in:

- 1 out of 10 documents  
- 5 out of 10  
- 9 out of 10  

Then ask:

- Which one is positive?  
- Which one is zero?  
- Which one is negative?  
- Which one should rank highest?  

This reinforces the intuition beautifully.

---

# ğŸ§  **Why BM25 Still Matters in 2026**

Even with vector search, embeddings, and RAG:

- BM25 is still the **best firstâ€‘stage retriever**  
- Itâ€™s fast, cheap, and interpretable  
- It handles exact keyword matching better than embeddings  
- Hybrid search = BM25 + vectors â†’ best of both worlds  

Your students will encounter BM25 everywhere:  
Elasticsearch, OpenSearch, Meilisearch, Vespa, Solr, and even WordPress plugins.

---

# ğŸ¯ **Final Takeaways**

- Negative BM25 scores are **normal**  
- Zero means **no match**  
- Higher scores always win, even if negative  
- BM25 is ranking-focused, not absolute-value-focused  
- Understanding IDF is the key to understanding everything else  

If your students walk away with one sentence, make it this:

> **BM25 doesnâ€™t care whether scores are positive or negative â€” it only cares about which document is the best match.**

